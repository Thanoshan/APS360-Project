{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "007-Sliding_Window_Single_Char.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Required modules"
      ],
      "metadata": {
        "id": "cDy4n63IPJ_9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4pGtTBMPDAv"
      },
      "outputs": [],
      "source": [
        "# Needed modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import *\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "use_cuda = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip serverside.zip\n",
        "#get from trevor "
      ],
      "metadata": {
        "id": "k9UgP8iLPWly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pillow-lut"
      ],
      "metadata": {
        "id": "gTjRpKRtPbnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from serverside.captcha.image import ImageCaptcha\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import string\n",
        "import random"
      ],
      "metadata": {
        "id": "Ry5mP-CiPhjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Generation\n"
      ],
      "metadata": {
        "id": "WBJNlQJXpkA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_string(length):\n",
        "    # choose from all lowercase letter\n",
        "    letters = \"abcdefghjkmnopqrstuvwxyz\" + \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" + \"123456789\" + \"     \"\n",
        "    result_str = ''.join(random.choice(letters) for i in range(length))\n",
        "    return result_str"
      ],
      "metadata": {
        "id": "l6KiYTcrpoqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Grayscale\n",
        "# Load datasets\n",
        "# Label formated as 2D tensor of indexed as [place][tokenID]\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz123456789 \" # use \" \" as null character. Leave out o and 0, also case insensitive\n",
        "charIndex = {}\n",
        "for i, char in enumerate(chars):\n",
        "    charIndex[char] = i\n",
        "\n",
        "idn = torch.eye(len(chars)).cuda()\n",
        "\n",
        "def strToOH(string):\n",
        "    oneHot = []\n",
        "    for char in string:\n",
        "      oneHot.append(idn[charIndex[char]])\n",
        "    return torch.stack(oneHot)\n",
        "\n",
        "def strToInd(string):\n",
        "    oneHot = []\n",
        "    for char in string:\n",
        "      oneHot.append(torch.tensor(charIndex[char]))\n",
        "    return torch.stack(oneHot)"
      ],
      "metadata": {
        "id": "xRn_E04wppR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TCacheSet():\n",
        "    def __init__(self, size, period):\n",
        "        self.size = size\n",
        "        self.cached = []\n",
        "        self.period = period\n",
        "        self.IC = ImageCaptcha(width = 25)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.flush()\n",
        "    def flush(self):\n",
        "        self.cached.clear()\n",
        "        for index in range(self.period):\n",
        "            label = get_random_string(1)\n",
        "            data = self.IC.generate_image(label)\n",
        "            data = self.transform(data)\n",
        "            label = label.lower().replace(\" \", \"\")\n",
        "            label += \" \" * (1 - len(label))\n",
        "\n",
        "            labelTensor = strToInd(label)\n",
        "            self.cached.append((data, labelTensor))\n",
        "    def __getitem__(self, index):\n",
        "        index = index % self.period\n",
        "        entry = self.cached[index]\n",
        "        return entry[0], entry[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "class TFrozenSet():\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "        self.cached = []\n",
        "        self.period = size\n",
        "        self.IC = ImageCaptcha(width = 25) # specify width to be 25, and then it will be resized to 224\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.flush2()\n",
        "    def flush2(self):\n",
        "        self.cached.clear()\n",
        "        for index in range(self.period):\n",
        "            label = get_random_string(1)\n",
        "            data = self.IC.generate_image(label)\n",
        "            data = self.transform(data)\n",
        "            label = label.lower().replace(\" \", \"\")\n",
        "            label += \" \" * (1 - len(label))\n",
        "\n",
        "            labelTensor = strToInd(label)\n",
        "            self.cached.append((data, labelTensor))\n",
        "    def __getitem__(self, index):\n",
        "        index = index % self.period\n",
        "        entry = self.cached[index]\n",
        "        return entry[0], entry[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size"
      ],
      "metadata": {
        "id": "MEm3eHXJpw4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainDataT = TCacheSet(12800, 1280)\n",
        "valDataT = TFrozenSet(3000)"
      ],
      "metadata": {
        "id": "9qkhsM5Gp3E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "31WhBPwWp4bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "resnet = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "_LG_IGj7p3tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class resnet_captcha(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(resnet_captcha, self).__init__()\n",
        "        self.name = \"res_cap\"\n",
        "        self.conv = resnet\n",
        "        self.fc1 = nn.Linear(1000, 500)  #width*height will change depending on previous layers, pooling, and the initial dimensions of the photo\n",
        "        self.fc2 = nn.Linear(500, 36)       # there are 36 possible characters, 26 letters (A-Z) and 10 digits (0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        x = x.view(-1, 1000)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = x.view(-1, len(chars), 1)\n",
        "        x = x.squeeze(1) # Flatten to [batch_size]\n",
        "        return x"
      ],
      "metadata": {
        "id": "-QukzqJxqAUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "LZOJaX7QqDZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "do_cuda = True\n",
        "\n",
        "def get_accuracy1(model, train=False, batch_size = 64):\n",
        "    if train:\n",
        "        data = trainDataT\n",
        "    else:\n",
        "        data = valDataT\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in tqdm(torch.utils.data.DataLoader(data, batch_size=batch_size)):\n",
        "        if use_cuda and torch.cuda.is_available:\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "          #pass\n",
        "\n",
        "        output = model(imgs)\n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def train_res_new(model, data, batch_size=64, num_epochs=30, learning_rate=0.0001):\n",
        "    torch.manual_seed(1000)\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "\n",
        "    startTime = time.time() # to see how long training goes\n",
        "    print(\"starting training\")\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        try:\n",
        "            data.flush()\n",
        "            train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\"epoch: \", epoch)\n",
        "        for imgs, labels in tqdm(iter(train_loader)):\n",
        "            #print(labels.shape)\n",
        "            if do_cuda and torch.cuda.is_available:\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "\n",
        "            out = model(imgs)             # forward pass\n",
        "            #print(out[0])\n",
        "            #print()\n",
        "            #print(labels[0])\n",
        "            #print()\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # save the current training information\n",
        "            iters.append(n)\n",
        "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "            n += 1\n",
        "\n",
        "        #train_acc.append(get_accuracy(model, train=True, batch_size=batch_size)) # compute training accuracy \n",
        "        val_acc.append(get_accuracy1(model, train=False, batch_size=batch_size))  # compute validation accuracy\n",
        "        print((\"Epoch {}: |\"+\"Validation acc: {}\").format(\n",
        "                epoch, # call epoch zero epoch zero\n",
        "                \n",
        "                val_acc[-1]))\n",
        "        \n",
        "        #checkpoint\n",
        "        path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(model.name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "\n",
        "    \n",
        "    finishTime = time.time()\n",
        "\n",
        "    delta = finishTime - startTime\n",
        "    print(\"\\nDONE TRAINING in %s seconds!\\n\" % delta)\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    #plt.plot(range(num_epochs), train_acc, label=\"Train\")\n",
        "    plt.plot(range(num_epochs), val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    #print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ],
      "metadata": {
        "id": "rxKFSHbaqLC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = resnet_captcha()\n",
        "print(torch.cuda.is_available())\n",
        "model2.cuda()\n",
        "train_res_new(model2,  trainDataT, num_epochs = 50, learning_rate = 0.001)"
      ],
      "metadata": {
        "id": "u2f1S0gDqPs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "\n",
        "Run everything here"
      ],
      "metadata": {
        "id": "jCda8ROBqTur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = plt.imread('/content/gdrive/path/to/test/image')\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "4QBTQyIKqWKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_w = torch.from_numpy(img_c).shape[1]\n",
        "c_h = torch.from_numpy(img_c).shape[0]\n",
        "print((\"shape is: {}x{}\").format(c_w, c_h))"
      ],
      "metadata": {
        "id": "iup_V7saqf06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "uBTcKu1PqjRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "O3bcEaJ7qwXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_windows = []\n",
        "captcha_w = img2.shape[1]\n",
        "transf = transforms.Resize((224, 224))\n",
        "      \n",
        "for i in range(0,captcha_w - window_w):\n",
        "    #print(c_w)\n",
        "    new_img = img2[:,i:(window_w+i),:]\n",
        "    if window_w != 224:\n",
        "        #new_img = transf(new_img)\n",
        "        #new_img = cv2.resize(new_img, (0,0 ), fx=224/window_w, fy=224/c_h)\n",
        "        #print(new_img.shape)\n",
        "\n",
        "\n",
        "        #new_img = np.tile(new_img, (1,9,1))\n",
        "        #new_img = new_img[:,:224,:]\n",
        "\n",
        "        #print(new_img.shape)\n",
        "        new_img = cv2.resize(new_img, (0,0 ), fx=224/window_w, fy=224/c_h)\n",
        "    img_windows.append(new_img)"
      ],
      "metadata": {
        "id": "FC_HchQjqp4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_to_tensor = transforms.ToTensor()\n",
        "for i in range(0, len(img_windows)):\n",
        "    img_windows[i] = img_to_tensor(np.array(img_windows[i]))\n",
        "\n",
        "print(img_windows[0].shape)"
      ],
      "metadata": {
        "id": "4zP-xfQCq1zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(img_windows)):\n",
        "    img_windows[i] = img_windows[i].unsqueeze(0)"
      ],
      "metadata": {
        "id": "A_HrzjlJq37s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.cuda()"
      ],
      "metadata": {
        "id": "J3rDHCf3rDoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will output a plot of the probability distribution across the image"
      ],
      "metadata": {
        "id": "M_aI0a4zrMA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#will store the probabilities \n",
        "distribution = [[0 for i in range(len(img_windows))] for j in range(36)]  # len(img_windows)x35 to hold all outputs for each window\n",
        "distribution = np.array(distribution)\n",
        "\n",
        "#dist_nosm = [[0 for i in range(len(img_windows))] for j in range(36)]  # len(img_windows)x35 to hold all outputs for each window\n",
        "#dist_nosm = np.array(dist_nosm)\n",
        "\n",
        "iter1 = 0\n",
        "prob_sum = 0\n",
        "for k in range(0, len(img_windows)): # for each window\n",
        "    img_windows[k] = img_windows[k].cuda()\n",
        "    pred = model2(img_windows[k])  #pred has shape 1x35 (will change to 36 once null is added)\n",
        "    #print(len(pred[0]))\n",
        "    for j in range(0, 36): # for each class\n",
        "        #print((\"k: {} | j: {}\").format(k, j))\n",
        "        \n",
        "        pred2 = torch.softmax(pred, dim=1) #apply softmax\n",
        "        if iter1 == 0:\n",
        "            for pr in range(36):\n",
        "                prob_sum = prob_sum + pred2[0][pr]\n",
        "            print((\"total prob is: {}\").format(prob_sum))\n",
        "            iter1 = iter1 + 1\n",
        "        #print(pred2[0][j])\n",
        "        arr = pred2[0][j]*100\n",
        "        distribution[j][k] = arr\n",
        "\n",
        "print(torch.max(torch.from_numpy(distribution)))\n",
        "chars_str = \"abcdefghijklmnopqrstuvwxyz123456789 \"\n",
        "plt.title(\"Character Distribution\")\n",
        "for ch in range(0, 36):\n",
        "    plt.plot(range(len(img_windows)), distribution[ch], label = chars_str[ch])\n",
        "    plt.xlabel(\"Captcha\")\n",
        "    plt.ylabel(\"Prob\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YLva_Ij8rIat"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}