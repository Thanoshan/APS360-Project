{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnRf9dgQpuaW"
      },
      "source": [
        "# **Milestone 1: Single Character Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_iga_UVpW4t"
      },
      "source": [
        "This is the notebook of our prototype single character classifier. This is the first milestone in our project, because being able to identify single characters is a prerequisite to identifying the characters used in the captcha "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77OpI8V5sW-Q"
      },
      "outputs": [],
      "source": [
        "#modules\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "use_cuda = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-t_27UVp3OH"
      },
      "source": [
        "# **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPYMd8gHqTBr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn71oxoRp7i6"
      },
      "outputs": [],
      "source": [
        "def load_data(batch_size = 64):\n",
        "    \n",
        "   \n",
        "  \n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    train_set = torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/path/to/train', transform=transform)\n",
        "    #print(train_set)\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_set = torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/path/to/val', transform=transform)\n",
        "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p7IATuGqX-n"
      },
      "source": [
        "# **The CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa5knx4aUg3C"
      },
      "outputs": [],
      "source": [
        "class char_cnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(char_cnn, self).__init__()\n",
        "        self.name = \"c_cnn\"\n",
        "        self.conv1 = nn.Conv2d(3, 5, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(5, 10, 5)\n",
        "        self.fc1 = nn.Linear(13*13*10, 100) # initial dimensions are a 64x64 pixel image\n",
        "        self.fc2 = nn.Linear(100, 62)       # there are 36 possible characters, 52 letters (A-Z, and a-z) and 10 digits (0-9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 13*13*10)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_xLFbu4qeLk"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MceTvckBm1Xt"
      },
      "outputs": [],
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUN1RepKm5X1"
      },
      "outputs": [],
      "source": [
        "# Training Curve\n",
        "def plot_training_curve(path):\n",
        "    \"\"\" Plots the training curve for a model run, given the csv files\n",
        "    containing the train/validation error/loss.\n",
        "\n",
        "    Args:\n",
        "        path: The base path of the csv files produced during training\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
        "    train_err = np.loadtxt(\"{}_train_err.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}_val_err.csv\".format(path))\n",
        "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    n = len(train_err) # number of epochs\n",
        "    plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Acc\")\n",
        "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Acc\")\n",
        "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(net, loader, criterion):\n",
        "    \"\"\" Evaluate the network on the validation set.\n",
        "\n",
        "     Args:\n",
        "         net: PyTorch neural network object\n",
        "         loader: PyTorch data loader for the validation set\n",
        "         criterion: The loss function\n",
        "     Returns:\n",
        "         err: A scalar for the avg classification error over the validation set\n",
        "         loss: A scalar for the average loss function over the validation set\n",
        "     \"\"\"\n",
        "    total_loss = 0.0\n",
        "    total_err = 0.0\n",
        "    total_epoch = 0\n",
        "    corr = 0.0\n",
        "    #net.cuda()\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        imgs, labels = data\n",
        "\n",
        "\n",
        "        imgs = imgs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "\n",
        "        out = net(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "\n",
        "        pred = out.max(1, keepdim=True)[1]\n",
        "        corr = pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total_err += len(labels)-int(corr)\n",
        "        total_loss += loss.item()\n",
        "        total_epoch += len(labels)\n",
        "    err = float(total_err) / total_epoch\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    return err, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model,batch_size=64, learning_rate=0.01,num_epochs=50):\n",
        "    torch.manual_seed(1000)\n",
        "    train_loader, val_loader = load_data(batch_size)\n",
        "  \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "\n",
        "    # Set up some numpy arrays to store the training/test loss/erruracy\n",
        "    train_err = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    train_acc = np.zeros(num_epochs)\n",
        "    val_err = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    val_acc = np.zeros(num_epochs)\n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    print((\"use_cuda is {}, torch.cuda.is_available() is {}\").format(use_cuda, torch.cuda.is_available()))\n",
        "    for epoch in range(num_epochs):\n",
        "        total_train_loss = 0.0\n",
        "        total_train_err = 0.0\n",
        "        total_train_acc = 0.0\n",
        "        total_epoch = 0\n",
        "        corr = 0.0\n",
        "        #print(\"epoch start\")\n",
        "        #for i in range(4):\n",
        "        #for data in iter(train_loader):\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            #print(\"start\")\n",
        "            imgs, labels = data\n",
        "            #print(imgs)\n",
        "            #print(labels)\n",
        "            #############################################\n",
        "            #To Enable GPU Usage\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                imgs = imgs.cuda()\n",
        "                labels = labels.cuda()\n",
        "            #############################################\n",
        "            #print(\"training start\")\n",
        "            out = model(imgs)             # forward pass\n",
        "            #print(out)\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            #print(\"training end\")\n",
        "            \n",
        "            pred = out.max(1, keepdim=True)[1]\n",
        "            corr = pred.eq(labels.view_as(pred)).sum().item()\n",
        "            #print((\"corr is {}, int(corr) is {}\").format(corr, int(corr)))\n",
        "\n",
        "            total_train_err += len(labels)-int(corr)\n",
        "            total_train_acc += (int(corr))\n",
        "\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            total_epoch += len(labels)\n",
        "            n = n+1\n",
        "\n",
        "\n",
        "            #print((\"n is {}, i is {}\").format(n,i))\n",
        "            #print(\"loss, accuracy, err calc done\")\n",
        "        #print(\"epoch end\")\n",
        "        train_err[epoch] = float(total_train_err) / total_epoch\n",
        "        train_acc[epoch] = float(total_train_acc) / total_epoch\n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "        #train_loss[epoch] = float(total_train_loss)\n",
        "        #model.cuda()\n",
        "        val_err[epoch], val_loss[epoch] = evaluate(model, val_loader, criterion)\n",
        "        val_acc[epoch] = 1-val_err[epoch]\n",
        "        print((\"Epoch {}: Train err: {}, Train loss: {}, Train acc: {} |\"+\n",
        "               \"Validation err: {}, Validation loss: {}, Validation Acc: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_err[epoch],\n",
        "                   train_loss[epoch],\n",
        "                   train_acc[epoch],\n",
        "                   val_err[epoch],\n",
        "                   val_loss[epoch],\n",
        "                   val_acc[epoch]))\n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    print('Finished Training')\n",
        "    # Write the train/test loss/err into CSV file for plotting later\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_err.csv\".format(model_path), train_err)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)     \n",
        "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_acc) \n",
        "    np.savetxt(\"{}_val_err.csv\".format(model_path), val_err)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)\n",
        "    np.savetxt(\"{}_val_acc.csv\".format(model_path), val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we actually instantiate / train:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sccnn = char_cnn()\n",
        "sccnn.cuda()\n",
        "train(sccnn)\n",
        "model_path = get_model_name(\"c_cnn\", batch_size=64, learning_rate=0.01, epoch=49)\n",
        "plot_training_curve(model_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Single Char Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
